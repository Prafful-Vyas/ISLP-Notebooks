{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Sales \\approx f(TV,Radio,Newspaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "- **Sales** ---- $Y$\n",
    "- **TV** ---- $X_1$\n",
    "- **Radio** ---- $X_2$\n",
    "- **Newspaper** ---- $X_3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show $input$ $vector$ as\n",
    "\n",
    "$$X = \\begin{pmatrix}\n",
    "X_1 \\\\\n",
    "X_2 \\\\\n",
    "X_3\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write our model as \n",
    "\n",
    "$$Y = f(X) + \\epsilon$$\n",
    "\n",
    "where $\\epsilon$ captures measurement errors and other discrepancies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is $f(X)$ good for?\n",
    "- With a good $f$ we can make predictions of $Y$ at new points $X = x$.\n",
    "- We can understand which components of $X = (X_1,X_2,...,X_p)$ are important in explaining $Y$, and which are irrelevant. e.g. **Seniority** and **Years of Education** have a big impact on Income, but **Marital Status** typically does not.\n",
    "- Depending on the complexity of $f$, we may be able to understand how each component $X_j$ of $X$ affects $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an ideal $f(X)$? In particular, what is a good value for $f(X)$ at any selected value of $X$, say $X=4$? There can be many $Y$ values at $X=4$. A good value is\n",
    "\n",
    "$$f(4) = E(Y|X=4)$$\n",
    "\n",
    "$E(Y|X=4)$ means $expected$ $value$ (average) of $Y$ given $X=4$.\n",
    "\n",
    "This ideal $f(x)=E(Y|X=x)$ is called $regression$ $function$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The regression function $f(x)$\n",
    "- Is also defined for vector $X$; e.g.\n",
    "    $$f(x)=f(x_1,x_2,x_3) = E(Y|X_1=x_1,X_2=x_2,X_3=x_3)$$\n",
    "\n",
    "- Is the $ideal$ or $optimal$ predictor of Y with regard to mean-squared prediction error: $f(x)=E(Y|X=x)$ is the function that minimizes $E[(Y-g(X))^2 | X=x]$ over all functions $g$ at all points $X=x$\n",
    "\n",
    "- $\\epsilon = Y - f(x)$ is the $irreducible$ error $-$ i.e. even if we knew $f(x)$, we would still make errors in prediction, since at each $X=x$ there is typically a distribution of possible $Y$ values.\n",
    "\n",
    "- For any estimate $\\hat{f}(x)$ of $f(x)$, we have\n",
    "    $$E[(Y-\\hat{f}(x))^2|X=x] = [f(x)-\\hat{f}(x)] + \\text{Var}(\\epsilon)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to estimate $f$\n",
    "- Typically we have few if any data points with $X = 4$ exactly.\n",
    "- So we cannot compute $E(Y|X=x)!$\n",
    "- Relax the definition and let\n",
    "$$\\hat{f}(x) = \\text{Ave}(Y|X \\in \\mathcal{N}(x))$$\n",
    "where $\\mathcal{N}(x)$ is some $neighborhood$ of $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nearest neighbor averaging can be pretty good for small $p$ $-$ i.e. $p \\le 4$ and large-ish $N$\n",
    "- We will discuss smoother versions, such as kernel and spline smoothing later in the course.\n",
    "- Nearest neighbor methods can be $lousy$ when $p$ is large. Reason: the $curse$ $of$ $dimensionality$. Nearest neighbors tend to be far away in high dimensions.\n",
    "\n",
    "    - We need to get a reasonable fraction of the $N$ values of $y_i$ to average to bring the variance down -- e.g. 10%.\n",
    "    - A 10% neighborhood in high dimensions need no longer be local, so we lose the spirit of estimating $E(Y|X=x)$ by local averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric and structured models\n",
    "The $linear$ model is an important example of a parametric model:\n",
    "$$ f_L(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\text{. . . }\\beta_pX_p.$$\n",
    "\n",
    "- A linear model is specified in terms of $p+1$ parameters $\\beta_0,\\beta_1\\text{,....,}\\beta_p.$\n",
    "\n",
    "- Although it is $almost$ $never$ $correct$, a linear model often serves as a good and interpretable approximation to the unknown true function $f(X).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model $\\hat{f}_L(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1X$ gives a reasonable fit here. {linear scatter}\n",
    "\n",
    "A quadratic model $\\hat{f}_Q(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1X + \\hat{\\beta}_2X^2$ fits slightly better. {quadratic scatter}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated example. Red points are simulated values for **income** from the model\n",
    "$$income = f(education,seniority) + \\epsilon$$\n",
    "$f$ is the blue surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression model fit to the simulated data.\n",
    "\n",
    "$$\\hat{f}_L(education,seniority) = \\hat{\\beta}_0 + \\hat{\\beta}_1*education + \\hat{\\beta}_2*seniority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More flexible regression model $\\hat{f}_S(education,seniority)$ fit to more simulated data. Here we use a technique called a $thin-plate$ $spline$ to fit a flexible surface. We control the roughness of the fit (chapter 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more flexible spline regression model\n",
    "$\\hat{f}_S(education,seniority)$ fit to the simulated data. Here the fitted model maked no errors on the training data!, Also known as $overfitting$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some trade-offs\n",
    "- Prediction accuracy versus interpretability.\n",
    "    $-$ Linear models are easy to interpret; thin-plate splines are not.\n",
    "- Good fit versus over-fit or under-fit.\n",
    "    $-$ How do we know when  the fit is just right?\n",
    "- Parsimony versus black-box.\n",
    "    $-$ We often prefer a simpler model involving fewer variables over a black-box predictor involving them all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models flexibility vs interpretability chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Model Accuracy\n",
    "\n",
    "Suppose we fit a model $\\hat{f}(x)$ to some training data $\\text{Tr} = \\{x_i,y_i\\}_{1}^N,$ and we wish to see how well it performs.\n",
    "- We could compute the average squared prediction error over $\\text{Tr}:$\n",
    "$$\\text{MSE}_{\\text{Tr}} = \\text{Ave}_{i \\in \\text{Tr}}[y_i - \\hat{f}(x_i)]^2$$\n",
    "This may be biased toward more overfit models.\n",
    "- Instead we should, if possible, compute it using fresh $test$ data $\\text{Te} = \\{x_i,y_i\\}_{1}^M:$\n",
    "$$\\text{MSE}_{\\text{Te}} = \\text{Ave}_{i \\in \\text{Te}}[y_i - \\hat{f}(x_i)]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charts; Black curve is truth. Red curve on right is $\\text{MSE}_\\text{Te},$ grey curve is $\\text{MSE}_\\text{Tr}.$ Orange, blue and green curves/squares correspond to fits of different flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charts; Here the truth is smoother, so the smoother fit and linear fit and linear model do really well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charts; Here the truth is wiggly and the noise is low, so the more flexible fits do the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-off\n",
    "\n",
    "Suppose we have to fit a model $\\hat{f}(x)$ to some training data $\\text{Tr},$ and let $(x_0,y_0)$ be a test observation drawn from the population. If the true model is $Y = f(X) + \\epsilon$ $(\\text{with } f(x) = E(Y|X=x))$, then\n",
    "\n",
    "$$ E(y_0 - \\hat{f}(x_0))^2 = \\text{Var}(\\hat{f}(x_0)) + [\\text{Bias}(\\hat{f}(x_0))]^2 + \\text{Var}(\\epsilon). $$\n",
    "\n",
    "The expectation averages over the variability of $y_0$ as well as the variability in $\\text{Tr}$. Note that $\\text{Bias}(\\hat{f}(x_0)) = E[\\hat{f}{(x_0)}] - f(x_0)$.\n",
    "\n",
    "Typically as the $flexibility$ of $\\hat{f}$ increases, its variance increases, and its bias decreases. So choosing the flexibility based on average test error amounts to a $bias-variance$ $trade-off$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart; Bias-variance trade-off for the three examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Problems\n",
    "\n",
    "Here the response variable $Y$ is $qualitative$ $-$ e.g. email is on of $C = (spam,ham)$  (**ham**=good email), digit class is one of $C = \\{0,1,. . . ,9\\}$. Our goals are to:\n",
    "- Build a classifier $C(X)$ that assigns a class label from $C$ to a future unlabeled observation $X$.\n",
    "- Assess the uncertainty in each classification\n",
    "- Understand the roles of the different predictors among $X = (X_1, X_2,\\text{. . . ,}X_p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an ideal $C(X)$? Suppose the $K$ elements in $C$ are numbered $1,2\\text{, . . . ,}K$. Let\n",
    "$$ p_k(x) = \\text{Pr}(Y=k|X=x), k=1,2,\\text{. . . ,}K.$$\n",
    "\n",
    "These are the $conditional$ $class$ $probabilities$ at $x$; e.g. see little barplot at $x=5.$ Then the $Bayes$ $optimal$ classifier at $x$ is\n",
    "$$C(x) = j\\text{ if } p_j(x)=\\text{max}\\{{p_1(x),p_2(x)\\text{, . . . ,}p_k(x)}\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest-neighbor averaging can be used as before.\n",
    "Also breaks down as dimension grows. However, the impact on $\\hat{C}(x)$ is less than on $\\hat{p}_k(x)\\text{, }k=1\\text{, . . . ,}K.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: some details\n",
    "- Typically we measure the performance of $\\hat{C}(x)$ using the misclassification error rate:\n",
    "$$\\text{Err}_{\\text{Te}} = \\text{Ave}_{i \\in \\text{Te}}I[y_i \\ne \\hat{C}(x_i)]$$\n",
    "\n",
    "- The Bayes classifier (using the true $p_k(x)$) has smallest error (in the population).\n",
    "\n",
    "- Support-vector machines build structured models for $C(x)$.\n",
    "- We will also build structured models for representing the $p_k(x)$. e.g. Logistic regression, generalized additive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: K-nearest neighbors in two dimensions\n",
    "K = 1(varies much); K=10(just right); K = 100(linear);\n",
    "\n",
    "train, test error vs 1/K chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
